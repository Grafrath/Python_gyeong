======================== 머신러닝 ========================
- 데이터 준비
- 모델 준비
- 모델 학습
- 모델 평가
- (그래프)

======================== Dataset Check ========================
<내장 데이터셋 확인 (scikit-learn)>
- data : 입력 데이터 (특성)
- target : 정답 데이터 (라벨/수치)
- feature_names : 특성(컬럼) 이름 확인 (예: age, bmi, bp 등)
- DESCR : 데이터셋에 대한 전체 설명

======================== models ========================

<KNN> K - 최근접 이웃 모델
- KNeighborsClassifier - 분류 : 가장 가까운 이웃들을 조사하여 클래스 판단
- KNeighborsRegressor - 예측 : 가장 가까운 이웃들을 조사하여 평균으로 예측

<LinearRegression> 선형 회귀
- LinearRegression - 예측 : 'y = ax + b'
    일반식 (y = a1x1 + a2x2 ... + anxn + b) 
    데이터를 가장 잘 대표하는 회귀선을 찾는다.
    즉, a b(파라미터)를 찾는 것.
    x = 특성 값, y = 에측 값
    손실함수 MSE 를 최소화 하는 a b를 찾는다 

<Ridge, Lasso> 릿지, 라쏘회귀
- Ridge - 예측 : 파라미터들을 규제하여 안정적인 모델학습 가능
    선형 회귀 손실함수(MSE)에 정규항 L2를 추가

- Lasso - 예측 : 파라미터들을 규제하여 안정적인 모델학습 가능
    선형 회귀 손실함수(MSE)에 정규항 L1를 추가
    필요없는 특성의 파라미터는 0으로 만들어 버림

<Logistic Regression> 로지스틱 리그레이션 : 이름은 회귀지만 이진 분류에 주로 사용.
    - 선형회귀의 선형방정식 결과를 시그모이드 함수에 통과시켜 0 or 1로 분류 문제 수행
    - 선형회귀의 선형방정식 결과 = z
        다중분류(ovr) - 이진분류를 여러개 독립적으로 수행
        다중분류(softmax) - 소프트맥스를 활용하여 한번에 수행

<점진적 학습> partial_fit
- 데이터를 한꺼번에 모두 준비하기 어려운 경우, 일부분씩 나누어 학습 가능
- 기존에 학습한 모델의 파라미터를 유지하며 업데이트함

<SGDClassifier> 확률적 경사 하강법 분류기
- 대용량 데이터 처리에 최적화된 점진적 학습 모델
- loss='log_loss': 로지스틱 회귀 모델로 동작
- loss='hinge': 서포트 벡터 머신(SVM) 모델로 동작
- 특징: 훈련 세트에서 샘플을 하나씩 꺼내어 경사 하강법을 수행함
- 주의: 반드시 스케일링(StandardScaler)된 데이터를 사용해야 함

<SGDRegressor> 확률적 경사 하강법 회귀 계열
- 대용량 데이터에서 연속적인 수치(예: 당뇨 수치)를 예측할 때 사용
- loss='squared_error': 일반적인 선형 회귀 손실 함수 사용
- 특징: Classifier와 마찬가지로 점진적 학습(partial_fit)이 가능함
- 주의: 특성 간 스케일 차이에 매우 민감하므로 반드시 스케일링 후 학습

<SVM> 서포트 벡터 머신
    - 데이터를 나누는 최적의 결정 경계(Hyperplane)를 찾는 모델
    - 마진(Margin): 결정 경계와 가장 가까운 데이터(Support Vector) 사이의 거리
    - 원리: 마진을 최대화하여 새로운 데이터에 대한 일반화 성능을 높임
    - 커널 트릭(Kernel Trick): 선형으로 나눌 수 없는 데이터를 고차원으로 보내 분리함
        - kernel='linear': 직선/평면으로 분리
        - kernel='rbf': (기본값) 복잡한 곡선/비선형 분리에 탁월

1. SVC (분류)
   - 목표: 클래스 간의 간격(Margin)을 최대화하여 분리.
   - 핵심: 데이터를 경계선 밖으로 밀어내어 확실히 구분하는 것.
   - 지표: Accuracy, F1-Score 등 분류 지표 사용.

2. SVR (회귀)
   - 목표: 제한된 오차(Epsilon) 범위 내에 최대한 많은 데이터를 포함.
   - 핵심: 데이터가 예측선 근처(통로 안)에 모여 있게 만드는 것.
   - 지표: MAE, MSE, R2 Score 등 회귀 지표 사용.

공통 주의사항:
- 두 모델 모두 C(규제)와 Gamma(영향력 범위) 파라미터에 민감함.
- 반드시 StandardScaler를 통해 데이터의 스케일을 맞춰야 성능이 보장됨.
3. 공통점
   - 커널 트릭(Kernel Trick) 사용 가능 (Linear, RBF 등)
   - 특성 스케일에 매우 민감함 (StandardScaler 필수)
   - C(규제): 클수록 오차 허용 안 함(예민함), 작을수록 마진을 넓힘(너그러움)

<SVM 시각화 및 커널 비교>
- Linear Kernel: 데이터를 직선(또는 초평면)으로 분리. 데이터가 선형적으로 명확히 나뉠 때 효율적임.
- RBF Kernel: 데이터를 곡선/원형 형태로 유연하게 분리. 대부분의 복잡한 실제 데이터에 기본적으로 사용됨.
- 결정 경계(Decision Boundary): 모델이 클래스를 구분하는 경계선. 마진이 최대화될수록 이 선이 데이터 사이의 한가운데를 지나게 됨.

<코드 팁: 시각화 원리>
- meshgrid: 평면을 아주 작은 격자로 나눔
- predict: 모든 격자점에 대해 0인지 1인지 예측
- contourf: 예측 결과에 따라 배경 색을 채워 경계를 표시

- 주요 하이퍼파라미터:
    - C (규제): 값이 클수록 오차를 엄격히 제한(과적합 주의), 작을수록 마진을 넓힘(과소적합 주의)
    - gamma: 데이터 하나당 영향력의 거리. 클수록 경계가 구불구불해지고 복잡해짐

- 주의: 거리 기반 모델이므로 반드시 StandardScaler로 스케일링 후 학습해야 함

======================== 머신러닝 = =======================
- 데이터 준비
- 모델 준비
- 모델 학습
- 모델 평가
- (그래프)

<스케일링>
필요한 경우 데이터를 스케일링 해주어야한다.
    - StandardScaler : 평균을 0, 표준편차 1 로 변환
    - MinMaxScaler : 최소값 0, 최대값 1 범위로 변환
    - RobustScaler : 중앙값과 IQR 사용해서 스케일링

<특성공학>
    - PolynomialFeatures : 특성을 인위적으로 늘리는 작업
    - Log Transformation : 데이터에 로그를 취하여 값의 범위를 압축
    - One-Hot Encoding : 범주형(문자) 데이터를 0과 1로 이루어진 여러 개의 특성으로 변환

<옵션탐색>
각 모델마다 최적의 옵션을 탐색하여 모델의 최고 성능을 뽑아내는 작업

======================== ETC ========================
<데이터 분할> train_test_split
    데이터 준비 과정에서 데이터를 훈련세트와 테스트 세트로 나누는 것

<평가 지표> Evaluation

- 분류(Classification): accuracy_score, confusion_matrix, f1_score, roc_auc_score
    - Accuracy (정확도): 전체 샘플 중 맞게 예측한 비율. 가장 직관적임
    - Confusion Matrix (혼동 행렬): 예측과 실제 정답의 관계를 4가지 경우로 구분한 표
        - TN: 0을 0으로 맞춤 / TP: 1을 1로 맞춤
        - FP (위양성): 실제 0을 1로 틀림 (오탐)
        - FN (위음성): 실제 1을 0으로 틀림 (미탐)
    - FPR (위양성률): 실제 0인 것들 중 모델이 1이라고 잘못 예측한 비율 (FP / FP + TN)
    - ROC-AUC: 위양성률(FPR) 대비 재현율(Recall)의 관계를 나타낸 지표. 1에 가까울수록 변별력이 높음

- 회귀(Regression): mean_absolute_error(MAE), mean_squared_error(MSE), r2_score
    - MAE: 실제값과 예측값 차이의 절대값 평균 (에러의 직관적인 크기)
    - MSE: 실제값과 예측값 차이의 제곱 평균. 에러가 클수록 벌칙을 크게 줌
    - RMSE: MSE에 루트를 씌운 값. 실제 데이터와 단위가 같아져 해석이 용이함
    - r2_score (결정계수): 모델이 데이터를 얼마나 잘 설명하는지 나타내는 지표 (1에 가까울수록 우수)

<F1 Score> 정밀도와 재현율의 균형 지표
- Precision (정밀도): 모델이 1이라고 예측한 것 중 실제 1인 비율 (예측 정확도)
- Recall (재현율): 실제 1인 것들 중 모델이 1이라고 맞춘 비율 (정답 적중률)
- F1 Score: 정밀도와 재현율의 조화 평균
    - 데이터 라벨 비율이 불균형할 때(예: 희귀병 양성/음성) 정확도(Accuracy)의 단점을 보완
    - 두 지표가 어느 한쪽으로 치우치지 않을 때 높은 점수가 나옴
    - 다중 분류 시에는 average 옵션(macro, weighted 등)을 사용함

======================== Tuning ========================

<GridSearchCV> 그리드 서치
하이퍼파라미터 탐색과 교차 검증을 한 번에 수행하는 도구

원리: 희망하는 파라미터 값들을 리스트로 전달하면, 모든 조합을 다 시도하여 최적의 조합을 찾아냄
특징: 단순히 점수만 계산하는 것이 아니라, 찾은 최적의 파라미터로 모델을 자동 재학습(refit)함

<주요 매개변수 및 속성>
params: 탐색할 파라미터 명과 값들을 담은 딕셔너리

cv: 교차 검증 분할 수 (기본값 5)
n_jobs: 사용할 CPU 코어 수 (-1로 설정하면 모든 코어 사용)

속성 확인:
    best_params_: 가장 좋은 성능을 낸 파라미터 조합
    best_score_: 최적 조합일 때의 교차 검증 평균 점수
    best_estimator_: 최적의 파라미터로 학습이 완료된 모델 객체

<RandomizedSearchCV> 랜덤 서치
파라미터 값이 수치형이거나 범위가 너무 넓어 모든 조합을 시도하기 어려울 때 사용
원리: 정해진 횟수(n_iter)만큼 파라미터 범위를 무작위로 샘플링하여 시도

특징: 그리드 서치보다 훨씬 빠르며, 최적의 결과에 근접한 값을 효율적으로 찾아냄

<Decision Tree> 의사결정 나무
- DecisionTreeClassifier / Regressor
    - 데이터를 특정 기준에 따라 가지치기하며 분류/예측
    - 스케일링의 영향이 적고 시각화가 쉬움

<Random Forest> 랜덤 포레스트
- RandomForestClassifier / Regressor
    - 여러 개의 결정 나무를 만들어 다수결 또는 평균으로 결정
    - 과적합(Overfitting) 방지에 효과적

<Boosting> 부스팅 (XGBoost, LightGBM)
- 점진적으로 오차를 줄여나가는 강력한 모델
- 파라미터 튜닝이 중요하며 성능이 매우 뛰어남

<Cross Validation> 교차 검증 (예: K-Fold)
- 데이터를 여러 조각으로 나누어 학습과 검증을 반복
- 특정 데이터셋에만 잘 작동하는 '운'을 배제함

======================== Validation ========================
<검증 세트> Validation Set
테스트 세트를 사용하지 않고 모델을 튜닝하기 위해 훈련 세트에서 추가로 떼어낸 데이터

훈련(sub): 모델 학습용 데이터
검증(val): 학습된 모델의 성능을 중간 점검하고 파라미터를 수정하는 용도
테스트(test): 모든 튜닝이 끝난 후 최종적으로 딱 한 번 성능 확인용

주의: 테스트 세트로 자꾸 성능을 확인하면 모델이 테스트 세트에 맞춰지는 '오염'이 발생함

<교차 검증> cross_validate
검증 세트를 나누느라 훈련 데이터가 줄어드는 단점을 보완하기 위해 사용
데이터를 K개의 조각(Fold)으로 나누어 모든 데이터가 한 번씩 검증에 사용되도록 반복 학습

원리: 훈련 데이터를 조각내어 돌아가며 검증용으로 쓰고, 나온 점수들의 평균을 냄
특징: 특정 데이터 세트에만 점수가 잘 나오는 '운'을 배제하여 모델의 일반화 능력을 확인 가능

<분할기> StratifiedKFold
분류 모델에서 타겟(라벨)의 비율이 훈련/검증 세트에 골고루 섞이도록 나누는 도구
shuffle=True: 데이터를 나누기 전 무작위로 섞음. 샘플 순서에 따른 편향을 막기 위해 필수적
n_splits: 데이터를 몇 조각으로 나눌지 설정 (보통 5 또는 10 사용)

======================== Ensemble ========================
<앙상블 학습> Ensemble Learning
여러 개의 모델을 결합하여 더 강력한 예측 성능을 내는 기법
대표적인 모델: 랜덤 포레스트, 엑스트라 트리, 그레이디언트 부스팅 등

<Random Forest> 랜덤 포레스트
결정 나무(Decision Tree)를 100개 모아 만든 숲
부트스트랩 샘플(Bootstrap Sample): 중복을 허용하여 데이터를 무작위로 추출해 각 나무를 학습시킴
특성 선택: 전체 특성 중 일부(특성 개수의 제곱근만큼)를 무작위로 골라 최적의 분할을 찾음

결론: 분류는 다수결, 회귀는 평균으로 최종 예측 수행. 과대적합 방지에 매우 강력함

<Extra Trees> 엑스트라 트리
랜덤 포레스트와 비슷하지만 더 '무작위성'이 강함
데이터 샘플링: 기본적으로 부트스트랩을 사용하지 않고 전체 샘플을 사용함

분할 방식: 최적의 임계값을 찾는 대신 무작위로 임계값을 설정하고 그중 가장 좋은 것을 선택
특징: 무작위성이 높아서 과대적합을 잘 막고, 계산 속도가 랜덤 포레스트보다 빠름

<회귀 모델 앙상블>
RandomForestRegressor: 여러 나무의 예측값의 평균을 최종 결과로 냄
ExtraTreesRegressor: 전체 데이터를 사용하되 무작위로 특징을 분할하여 평균을 냄

특징: 분류(Classifier)와 달리 결정계수($R^2$)나 MSE 등으로 성능을 평가함

<Gradient Boosting> 그라디언트 부스팅
오차를 순차적으로 줄여나가는 앙상블 학습 기법

원리: 얕은 나무를 순차적으로 추가하며, 이전 나무가 예측한 오차를 다음 나무가 학습하여 보완함

특징: 랜덤 포레스트보다 일반적으로 정확도가 높지만, 순차적으로 학습하므로 속도가 느림
장점: 경사 하강법을 사용하여 오차를 최소화하므로 매우 정교한 모델 생성이 가능

======================== Pipeline ========================
<파이프라인> Pipeline

데이터 전처리 단계(예: 스케일링)와 모델 학습 단계를 하나로 묶어주는 도구

사용 이유: 교차 검증 시, 검증 세트의 정보가 훈련 세트로 새어나가는 '데이터 누수'를 방지하기 위함
작동 원리: 교차 검증의 매 폴드마다 훈련 데이터만 스케일링하여 모델을 학습시키고,
그 기준으로 검증 데이터를 변환함

<파이프라인과 그리드 서치>

매개변수 지정: 모델명__파라미터명 (언더바 2개 __ 사용)

예: ridge__alpha, svr__C
장점: 여러 모델의 전처리 과정을 표준화하여 코드가 깔끔해짐

======================== Evaluation Rules ========================
<사이킷런의 점수 체계> Scoring

사이킷런의 scoring 옵션은 항상 "클수록 좋은 값"을 기준으로 설계됨
neg_root_mean_squared_error: RMSE는 작을수록 좋으므로, 앞에 마이너스(-)를 붙여서 큰 값이 좋은 것처럼 만듦

복구 방법: 최종 점수를 확인할 때는 다시 마이너스를 붙여서(-grid.best_score_) 양수로 변환해 사용

<평가 지표 추가>

RMSE (Root Mean Squared Error): MSE에 루트를 씌워 실제 데이터와 단위를 맞춘 에러 지표
R2 Score (결정계수): 모델이 데이터를 얼마나 잘 설명하는지 (1에 가까울수록 우수, 0이면 평균 모델 수준)

======================== Model Comparison ========================
<모델별 특징 요약>

Ridge: 선형 모델. 반드시 스케일링 필요. alpha로 규제 강도 조절
SVR: 거리 기반 모델. 반드시 스케일링 필요. C, gamma, epsilon 파라미터에 매우 민감함
Random Forest: 트리 기반 모델. 스케일링이 불필요함. 데이터의 절대적인 크기보다 순서가 중요하기 때문

### 1. 데이터 준비 및 전처리 (Preprocessing)
내장 데이터셋 확인 (scikit-learn)
data: 입력 데이터 (특성) / target: 정답 데이터 (라벨/수치)
feature_names: 특성(컬럼) 이름 / DESCR: 데이터셋 전체 설명

데이터 분할 (train_test_split)
데이터를 훈련(Train) / 테스트(Test) 세트로 분리

검증 세트(Validation): 모델 튜닝을 위해 훈련 세트에서 추가로 떼어낸 데이터
스케일링 (Scaling): 거리 기반 모델 필수

StandardScaler: 평균 0, 표준편차 1 변환
MinMaxScaler: 0~1 범위 변환
RobustScaler: 중앙값과 IQR 사용 (이상치에 강함)

특성공학 (Feature Engineering)

PolynomialFeatures: 특성을 인위적으로 생성/증식
Log Transformation: 값의 범위를 압축하여 정규성 확보
One-Hot Encoding: 범주형 데이터를 0과 1의 특성으로 변환

### 2. 모델별 특징 (Model Zoo)
선형 및 거리 기반 모델 (스케일링 필수)

KNN (K-최근접 이웃)

KNeighborsClassifier: 이웃의 클래스로 판단
KNeighborsRegressor: 이웃의 평균값으로 예측

Linear Regression (선형 회귀)
손실함수(MSE)를 최소화하는 파라미터(a, b)를 찾는 과정

Ridge / Lasso (규제 회귀)
Ridge: L2 규제 추가. 파라미터를 안정적으로 제한
Lasso: L1 규제 추가. 중요하지 않은 특성의 파라미터를 0으로 만듦

Logistic Regression
이름은 회귀지만 이진 분류에 사용 (시그모이드 함수 통과)
다중 분류 시 ovr(독립 수행) 또는 softmax(한번에 수행) 활용

SVM (서포트 벡터 머신)
최적의 결정 경계(Hyperplane)와 최대 마진(Margin)을 찾는 모델
SVC (분류): 클래스 간 간격 최대화 / SVR (회귀): 오차 범위 내 데이터 포함
커널 트릭: linear(직선), rbf(곡선/비선형)로 고차원 분리 가능

트리 기반 및 앙상블 모델 (스케일링 영향 적음)
Decision Tree (의사결정 나무)

기준에 따른 가지치기. 시각화가 쉽고 과적합 위험 있음

Random Forest (랜덤 포레스트)

결정 나무 100개를 모은 숲. 부트스트랩 샘플 사용
분류는 다수결, 회귀는 평균으로 결정. 과대적합 방지에 강력함

Extra Trees (엑스트라 트리)

랜덤 포레스트보다 더 무작위함. 속도가 빠르고 과대적합 방지 탁월

Gradient Boosting (그라디언트 부스팅)

얕은 나무를 순차적으로 추가하며 이전 나무의 오차를 보완. 정확도 높음

### 3. 학습 및 검증 기법 (Learning & Validation)
점진적 학습 (partial_fit)

데이터를 나누어 학습 가능. 기존 파라미터를 유지하며 업데이트
SGDClassifier, SGDRegressor: 대용량 데이터에 최적화된 확률적 경사 하강법

교차 검증 (cross_validate)

데이터를 K개의 조각(Fold)으로 나누어 반복 검증 (일반화 성능 확인)
StratifiedKFold: 분류 시 타겟 비율을 골고루 섞어 나눔

### 4. 튜닝 및 최적화 (Tuning)
GridSearchCV / RandomizedSearchCV

최적의 하이퍼파라미터 조합 탐색 및 교차 검증 자동 수행
best_params_, best_score_, best_estimator_ 속성 활용

Pipeline (파이프라인)

전처리 단계와 모델 학습 단계를 하나로 결합
데이터 누수 방지: 교차 검증 시 폴드별로 전처리를 독립 수행

### 5. 평가 지표 (Evaluation)
사이킷런 scoring 공통 규칙

점수 체계: 항상 "클수록 좋은 값"을 기준으로 설계됨
마이너스(-) 부호: RMSE처럼 작을수록 좋은 지표는 앞에 마이너스를 붙여 제공 (neg_root_mean_squared_error)

복구: 최종 점수 확인 시 다시 마이너스를 붙여 양수로 변환 필요 (-grid.best_score_)

분류(Classification)
accuracy_score, confusion_matrix, f1_score, roc_auc_score
    - Accuracy (정확도): 전체 샘플 중 맞게 예측한 비율. 가장 직관적임
    - Confusion Matrix (혼동 행렬): 예측과 실제 정답의 관계를 4가지 경우로 구분한 표
        - TN: 0을 0으로 맞춤 / TP: 1을 1로 맞춤
        - FP (위양성): 실제 0을 1로 틀림 (오탐)
        - FN (위음성): 실제 1을 0으로 틀림 (미탐)
    - FPR (위양성률): 실제 0인 것들 중 모델이 1이라고 잘못 예측한 비율 (FP / FP + TN)
    - ROC-AUC: 위양성률(FPR) 대비 재현율(Recall)의 관계를 나타낸 지표. 1에 가까울수록 변별력이 높음

회귀(Regression)
mean_absolute_error(MAE), mean_squared_error(MSE), r2_score
    - MAE: 실제값과 예측값 차이의 절대값 평균 (에러의 직관적인 크기)
    - MSE: 실제값과 예측값 차이의 제곱 평균. 에러가 클수록 벌칙을 크게 줌
    - RMSE: MSE에 루트를 씌운 값. 실제 데이터와 단위가 같아져 해석이 용이함
    - r2_score (결정계수): 모델이 데이터를 얼마나 잘 설명하는지 나타내는 지표 (1에 가까울수록 우수)
'''

======================== models ========================

<KNN> K - 최근접 이웃 모델
- KNeighborsClassifier - 분류 : 가장 가까운 이웃들을 조사하여 클래스 판단
- KNeighborsRegressor - 예측 : 가장 가까운 이웃들을 조사하여 평균으로 예측

<LinearRegression> 선형 회귀
- LinearRegression - 예측 : 'y = ax + b'
    일반식 (y = a1x1 + a2x2 ... + anxn + b)
    데이터를 가장 잘 대표하는 회귀선을 찾는다.
    즉, a b(파라미터)를 찾는 것.
    x = 특성 값, y = 에측 값
    손실함수 MSE 를 최소화 하는 a b를 찾는다

<Ridge, Lasso> 릿지, 라쏘회귀
- Ridge - 예측 : 파라미터들을 규제하여 안정적인 모델학습 가능
    선형 회귀 손실함수(MSE)에 정규항 L2를 추가

- Lasso - 예측 : 파라미터들을 규제하여 안정적인 모델학습 가능
    선형 회귀 손실함수(MSE)에 정규항 L1를 추가
    필요없는 특성의 파라미터는 0으로 만들어 버림

======================== 머신러닝 ========================
- 데이터 준비
- 모델 준비
- 모델 학습
- 모델 평가
- (그래프)

'''

'''

<스케일링>
필요한 경우 데이터를 스케일링 해주어야한다.
    - StandardScaler : 평균을 0, 표준편차 1 로 변환
    - MinMaxScaler : 최소값 0, 최대값 1 범위로 변환
    - RobustScaler : 중앙값과 IQR 사용해서 스케일링

<특성공학>
    - PolynomialFeatures : 특성을 인위적으로 늘리는 작업
    - Log Transformation : 데이터에 로그를 취하여 값의 범위를 압축
    - One-Hot Encoding : 범주형(문자) 데이터를 0과 1로 이루어진 여러 개의 특성으로 변환

<옵션탐색>
각 모델마다 최적의 옵션을 탐색하여 모델의 최고 성능을 뽑아내는 작업

'''

'''
1. 검증 세트 (Validation Set)
개념: 테스트 세트를 사용하지 않고 모델을 평가하기 위해, 훈련 세트에서 다시 한 번 떼어낸 데이터입니다.

이유: 테스트 세트로 자꾸 확인하면 모델이 테스트 세트에만 맞춰지는 '오염'이 발생하기 때문입니다.

데이터 분할: 훈련(60%) / 검증(20%) / 테스트(20%)

2. 교차 검증 (Cross Validation)
개념: 검증 세트를 고정하지 않고, 데이터를 여러 덩어리(Fold)로 나눠 번갈아가며 검증하는 방식입니다.

장점: 데이터가 적을 때 효율적이며, 특정 검증 세트에 편향되는 것을 방지하여 모델의 일반화 성능을 높입니다. (예: k-폴드 교차 검증)

3. 그리드 서치 (Grid Search)
개념: 탐색할 하이퍼파라미터 값들을 리스트로 전달하면, 모든 조합을 다 시도해보고 가장 좋은 성능의 옵션을 찾습니다.

특징: GridSearchCV를 사용하면 교차 검증과 하이퍼파라미터 탐색을 동시에 수행해줍니다.

4. 랜덤 서치 (Random Search)
개념: 값을 지정하는 대신 **확률 분포(범위)**를 주고, 그 안에서 랜덤하게 값을 뽑아 시도합니다.

특징: 파라미터 범위가 너무 넓거나, 어떤 값이 중요한지 모를 때 그리드 서치보다 훨씬 빠르고 효율적입니다.
'''